{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./input/elliptic_txs_features_test.csv\n",
      "./input/elliptic_txs_classes.csv\n",
      "./input/elliptic_txs_edgelist.csv\n",
      "./input/elliptic_txs_features.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('./input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "id_time=[\"txId\", \"time_step\"]\n",
    "feature_names = ['feature_'+str(i) for i in range(1,166)]\n",
    "column_names = id_time + feature_names\n",
    "elliptic_classes = pd.read_csv('./input/elliptic_txs_classes.csv')\n",
    "elliptic_classes.columns = ['txId', 'class_label']\n",
    "elliptic_edgelist = pd.read_csv('./input/elliptic_txs_edgelist.csv')\n",
    "elliptic_features = pd.read_csv('./input/elliptic_txs_features.csv', names=column_names)\n",
    "elliptic_features[\"centrality\"] =None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import EllipticBitcoinDataset\n",
    "#from torch_geometric.logging import init_wandb, log\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "dataset = EllipticBitcoinDataset(root='./pytorch_input')\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x: Node feature matrix of shape [num_nodes, in_channels]\n",
    "        # edge_index: Graph connectivity matrix of shape [2, num_edges]\n",
    "        #x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv2(x, edge_index).relu()\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.156799077987671 0.023357382615070026 0.024350800808583425\n",
      "2 2.045508623123169 0.03886724024846638 0.04046027056445343\n",
      "3 1.9586296081542969 0.0637138778502257 0.06443787902348001\n",
      "4 1.8785839080810547 0.09489563640572553 0.09466645933758358\n",
      "5 1.8077332973480225 0.12873181835718972 0.12753848546104804\n",
      "6 1.7099274396896362 0.16363285620587215 0.16404913699269166\n",
      "7 1.652165174484253 0.20097225973224275 0.20301663815891774\n",
      "8 1.5695149898529053 0.2442378178170454 0.24605815580780593\n",
      "9 1.5155141353607178 0.2909911647825919 0.2919919141657596\n",
      "10 1.4614330530166626 0.33631698753809947 0.33730368527445187\n",
      "11 1.4131238460540771 0.3754234345460859 0.3765199813403825\n",
      "12 1.3671588897705078 0.41300976117905785 0.4140880111957705\n",
      "13 1.3385276794433594 0.4434893321501601 0.4448452806717462\n",
      "14 1.293747067451477 0.46601334928045063 0.4666148343958949\n",
      "15 1.2611244916915894 0.4840078706740229 0.48356398693826774\n",
      "16 1.2218513488769531 0.49596820865002506 0.49675011662260926\n",
      "17 1.1904600858688354 0.5057756857903468 0.5065153164360131\n",
      "18 1.1675591468811035 0.513607778077858 0.5133571761778883\n",
      "19 1.1425930261611938 0.5192407114472009 0.5179909811848857\n",
      "20 1.116165041923523 0.5231837648057409 0.5216607059555279\n"
     ]
    }
   ],
   "source": [
    "simplemodel = GCN(dataset.num_features, 32, dataset.num_classes+1)\n",
    "data=dataset[0]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "labeled = data.y>0\n",
    "randomize = torch.FloatTensor(data.y.shape[0]).uniform_()\n",
    "classweight = torch.FloatTensor([0,int((data.y == 2).sum()),int((data.y == 1).sum())])\n",
    "data.train_mask = torch.logical_and(data.y > 0,randomize>0.2)# 80% of labeled\n",
    "data.test_mask = torch.logical_and(data.y > 0,randomize< 0.2)# rest 20% of labeled\n",
    "# init_wandb(name=f'GCN-{args.dataset}', lr=args.lr, epochs=args.epochs,            hidden_channels=args.hidden_channels, device=device)\n",
    "simplemodel, data = simplemodel.to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam([ dict(params=simplemodel.conv1.parameters(), weight_decay=5e-4), \n",
    "dict(params=simplemodel.conv2.parameters(), weight_decay=0),\n",
    "dict(params=simplemodel.conv3.parameters(), weight_decay=0)], lr=0.001)  # Only perform weight-decay on first convolution.\n",
    "\n",
    "\n",
    "def train(model):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    #print(out.shape,new_y.shape)\n",
    "    #print(data.y[data.test_mask].shape)\n",
    "    loss = F.cross_entropy(out[data.train_mask], data.y[data.train_mask],weight=classweight)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    pred = model(data.x, data.edge_index).argmax(dim=-1)\n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.test_mask]:\n",
    "        accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
    "    return accs\n",
    "\n",
    "\n",
    "best_val_acc = final_test_acc = 0\n",
    "for epoch in range(1, 21):\n",
    "    loss = train(simplemodel)\n",
    "    train_acc, tmp_test_acc = test(simplemodel)\n",
    "    print(epoch,loss,train_acc,tmp_test_acc)\n",
    "    #log(Epoch=epoch, Loss=loss, Train=train_acc, Val=0, Test=test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate New Centrality Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7880\n",
      "4544\n",
      "6621\n",
      "5693\n",
      "6803\n",
      "4328\n",
      "6048\n",
      "4457\n"
     ]
    }
   ],
   "source": [
    "time_steps = list(range(1,17))\n",
    "graphs = []\n",
    "for time_step in time_steps:\n",
    "    extract_nodes = list(set(elliptic_features[elliptic_features['time_step']==time_step]['txId'].values.tolist()))\n",
    "    edgelist_extract = elliptic_edgelist[elliptic_edgelist['txId1'].isin(extract_nodes) & elliptic_edgelist['txId2'].isin(extract_nodes)].values.tolist()\n",
    "    edgelist = [tuple(row) for row in edgelist_extract]\n",
    "    G = nx.DiGraph()\n",
    "    G.add_edges_from(edgelist)\n",
    "    graphs.append(G)\n",
    "    centrality = nx.in_degree_centrality(G)\n",
    "    print(len(centrality.keys()))\n",
    "    for id in centrality.keys():\n",
    "        elliptic_features.loc[(elliptic_features[\"txId\"] == id) &(elliptic_features['time_step']==time_step) ,\"centrality\"] = centrality[id]\n",
    "    #elliptic_features = pd.merge(elliptic_features,subset[[\"txId\",\"time_step\",\"new\"]],on = [\"txId\",\"time_step\"],how=\"left\")\n",
    "    #print(time_step,len(subset),len(centrality))\n",
    "extract_nodes = list(set(elliptic_features[elliptic_features['time_step'].isin(time_steps)]['txId'].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = dataset[0]\n",
    "new.x = elliptic_features\n",
    "new.x = torch.Tensor(new.x[new.x.columns[2:]].values.astype(np.float32))\n",
    "modelnew = GCN(dataset.num_features+1, 16, dataset.num_classes+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_acc = final_test_acc = 0\n",
    "for epoch in range(1, 21):\n",
    "    loss = train(modelnew)\n",
    "    train_acc, tmp_test_acc = test(modelnew)\n",
    "    print(epoch,loss,train_acc,tmp_test_acc)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
